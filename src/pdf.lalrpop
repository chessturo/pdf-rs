use crate::ast::object;
use crate::lexer::*;
use crate::parser_helper::*;

grammar<'input>(input: &'input [u8]);

////////////////////////////// !!! IMPORTANT !!! //////////////////////////////
// Due to interesting choices made in writing the PDF spec, it generally makes
// more sense to iterate over the token stream backwards rather than forwards.
// For example, consider the array `[0 0 R]`. If we go token-by-token forwards,
// we have an inevitable shift/reduce conflict because we cannot tell whether
// to parse the first integer as a "true" integer without more than one token
// of lookahead to see the `R`. If we go token-by-token backwards, however,
// this problem (and others, like difficulties with incremental updates) are
// actually avoided. Unfortunately, this makes the grammar much harder to read
//
// :(
//
// Note that only the token *stream* is backwards. The *contents* of tokens
// (e.g., the &[u8] slices into the input) are the right way around.

pub RawPdfStr: Vec<u8> = ")" <RawStrContent?> "(" =>
    handle_raw_str_escapes(<>.unwrap_or(&[]));

// TODO: Don't `.unwrap()` if there's invalid hex characters
pub HexPdfStr: Vec<u8> = ">" <HexStrContent?> "<" => handle_hex_str(<>.unwrap_or(&[])).unwrap();
pub Name: Vec<u8> = NameTok => handle_name_escapes(<>).unwrap();

pub Boolean: bool = {
    "true" => true,
    "false" => false,
}

pub Number: object::Number = {
    <NumberTok> => handle_number(<>),
}

extern {
    type Location = usize;
    type Error = PdfLexError<'input>;

    enum Tok<'input> {
        "(" => Tok::RawStrDelimOpen,
        ")" => Tok::RawStrDelimClose,
        RawStrContent => Tok::RawStrContent(<&'input [u8]>),

        "<" => Tok::HexStrDelimOpen,
        ">" => Tok::HexStrDelimClose,
        HexStrContent => Tok::HexStrContent(<&'input [u8]>),

        NameTok => Tok::Name(<&'input [u8]>),

        "true" => Tok::True,
        "false" => Tok::False,

        NumberTok => Tok::Number(<&'input [u8]>),

        UnknownTok => Tok::UnknownTok(<&'input [u8]>),
    }
}
